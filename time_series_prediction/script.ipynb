{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math, keras, datetime, pandas as pd, numpy as np, keras.backend as K\n",
    "import matplotlib.pyplot as plt, xgboost, operator, random, pickle\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "import glob, re\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Introduction\n",
    "# This is an initial Exploratory Data Analysis for the Recruit Restaurant Visitor Forecasting \n",
    "\n",
    "# The aim of this challenge is to predict the future numbers of restaurant visitors. \n",
    "# This makes it a Time Series Forecasting problem. The data was collected from Japanese restaurants.\n",
    "# As we will see, the data set is small and easily accessible without requiring much memory or computing power. \n",
    "# Therefore, this competition is particularly suited for beginners.\n",
    "\n",
    "# The data comes in the shape of 8 relational files which are derived from two separate Japanese websites that \n",
    "# collect user information: “Hot Pepper Gourmet (hpg): similar to Yelp” (search and reserve) \n",
    "# and “AirREGI / Restaurant Board (air): similar to Square” (reservation control and cash register). \n",
    "# The training data is based on the time range of Jan 2016 - most of Apr 2017, \n",
    "# while the test set includes the last week of Apr plus May 2017. \n",
    "# The test data “intentionally spans a holiday week in Japan called the ‘Golden Week.’ \n",
    "# The data description further notes that:”There are days in the test set where the restaurant were \n",
    "# closed and had no visitors. These are ignored in scoring. The training set omits days where the restaurants \n",
    "# were closed.\"\n",
    "\n",
    "# Those are the individual files:\n",
    "\n",
    "# air_visit_data.csv: historical visit data for the air restaurants. \n",
    "# This is essentially the main training data set.\n",
    "\n",
    "# air_reserve.csv / hpg_reserve.csv: reservations made through the air / hpg systems.\n",
    "\n",
    "# air_store_info.csv / hpg_store_info.csv: details about the air / hpg restaurants including genre and location.\n",
    "\n",
    "# store_id_relation.csv: connects the air and hpg ids\n",
    "\n",
    "# date_info.csv: essentially flags the Japanese holidays.\n",
    "\n",
    "# sample_submission.csv: serves as the test set. The id is formed by combining the air id with the visit date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_df(left, right, left_on, right_on=None):\n",
    "    if right_on is None: right_on = left_on\n",
    "    return left.merge(right, how='left', left_on=left_on, right_on=right_on, \n",
    "                      suffixes=(\"\", \"_y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'air_visits':  pd.read_csv('../input/air_visit_data.csv'),\n",
    "    'air_reserve': pd.read_csv('../input/air_reserve.csv'),\n",
    "    'hpg_reserve': pd.read_csv('../input/hpg_reserve.csv'),\n",
    "    'air_store':   pd.read_csv('../input/air_store_info.csv'),\n",
    "    'hpg_store':   pd.read_csv('../input/hpg_store_info.csv'),\n",
    "    'holidays':    pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'}),\n",
    "    'store_ids':   pd.read_csv('../input/store_id_relation.csv'),\n",
    "    'test':        pd.read_csv('../input/sample_submission.csv')\n",
    "# test_df = pd.read_csv('../input/sample_submission.csv') \n",
    "    }\n",
    "\n",
    "## Associate hpg store id with air store id\n",
    "data['hpg_reserve'] = pd.merge(data['hpg_reserve'], data['store_ids'], how='inner', on=['hpg_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data['test'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ['air_reserve', 'hpg_reserve']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>rs1</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rs2</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  rs1  rv1  rs2  rv2\n",
       "0  air_00a91d42b08b08d9  2016-01-14    3    2  3.0  2.0\n",
       "1  air_00a91d42b08b08d9  2016-01-15    6    4  6.0  4.0\n",
       "2  air_00a91d42b08b08d9  2016-01-16    3    2  3.0  2.0\n",
       "3  air_00a91d42b08b08d9  2016-01-22    3    2  3.0  2.0\n",
       "4  air_00a91d42b08b08d9  2016-01-29    6    5  6.0  5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(18620, 6)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data['hpg_reserve'].head())\n",
    "np.shape(data['hpg_reserve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>rs1</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rs2</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  rs1  rv1  rs2   rv2\n",
       "0  air_00a91d42b08b08d9  2016-10-31    0    2  0.0   2.0\n",
       "1  air_00a91d42b08b08d9  2016-12-05    4    9  4.0   9.0\n",
       "2  air_00a91d42b08b08d9  2016-12-14    6   18  6.0  18.0\n",
       "3  air_00a91d42b08b08d9  2016-12-17    6    2  6.0   2.0\n",
       "4  air_00a91d42b08b08d9  2016-12-20    2    4  2.0   4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(29830, 6)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data['air_reserve'].head())\n",
    "np.shape(data['air_reserve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"preprocess training data spliting out the dates \"\"\"\n",
    "data['air_visits']['visit_date'] = pd.to_datetime(data['air_visits']['visit_date'])\n",
    "data['air_visits']['dow'] = data['air_visits']['visit_date'].dt.dayofweek\n",
    "data['air_visits']['year'] = data['air_visits']['visit_date'].dt.year\n",
    "data['air_visits']['month'] = data['air_visits']['visit_date'].dt.month\n",
    "data['air_visits']['visit_date'] = data['air_visits']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  dow  year  month  visitors\n",
       "0  air_ba937bf13d40fb24  2016-01-13    2  2016      1        25\n",
       "1  air_ba937bf13d40fb24  2016-01-14    3  2016      1        32\n",
       "2  air_ba937bf13d40fb24  2016-01-15    4  2016      1        29\n",
       "3  air_ba937bf13d40fb24  2016-01-16    5  2016      1        22\n",
       "4  air_ba937bf13d40fb24  2016-01-18    0  2016      1         6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = data['air_visits'].columns.tolist()\n",
    "cols =  cols[0:2] + cols[3:] + cols[2:3] \n",
    "data['air_visits'] = data['air_visits'][cols]\n",
    "display(data['air_visits'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"prepocess test set to match training dimensions\"\"\"\n",
    "data['test']['air_store_id'] = data['test']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['test']['visit_date'] = data['test']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['test']['visit_date'] = pd.to_datetime(data['test']['visit_date'])\n",
    "data['test']['dow'] = data['test']['visit_date'].dt.dayofweek\n",
    "data['test']['year'] = data['test']['visit_date'].dt.year\n",
    "data['test']['month'] = data['test']['visit_date'].dt.month\n",
    "data['test']['visit_date'] = data['test']['visit_date'].dt.date\n",
    "\n",
    "unique_stores = data['test']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores,\n",
    "                                  'dow': [i]*len(unique_stores)}) \n",
    "                    for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  dow  year  month  visitors\n",
       "0  air_00a91d42b08b08d9  2017-04-23    6  2017      4         0\n",
       "1  air_00a91d42b08b08d9  2017-04-24    0  2017      4         0\n",
       "2  air_00a91d42b08b08d9  2017-04-25    1  2017      4         0\n",
       "3  air_00a91d42b08b08d9  2017-04-26    2  2017      4         0\n",
       "4  air_00a91d42b08b08d9  2017-04-27    3  2017      4         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# columnsTitles=[\"visitors\",\"A\"]\n",
    "# df=df.reindex(columns=columnsTitles)\n",
    "cols = data['test'].columns.tolist()\n",
    "cols =  cols[2:] + cols[1:2] \n",
    "data['test'] = data['test'][cols]\n",
    "display(data['test'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We can compress the rows into meaningful features and combine genre, location datasets into our training sets\n",
    "    save into stores as a temp variable\"\"\"\n",
    "\n",
    "tmp = data['air_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['air_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['air_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['air_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['air_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "\n",
    "stores = pd.merge(stores, data['air_store'], how='left', on=['air_store_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data['holidays'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['holidays']['visit_date'] = pd.to_datetime(data['holidays']['visit_date'])\n",
    "data['holidays']['visit_date'] = data['holidays']['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['holidays'].holiday_flg = data['holidays'].holiday_flg != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['holidays']['calendar_date'] = pd.to_datetime(data['holidays']['calendar_date'])\n",
    "# data['holidays']['calendar_date'] = data['holidays']['calendar_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(data['air_visits'], data['holidays'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['test'], data['holidays'], how='left', on=['visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def join_df(left, right, left_on, right_on=None):\n",
    "#     if right_on is None: right_on = left_on\n",
    "#     return left.merge(right, how='left', left_on=left_on, right_on=right_on, \n",
    "#                       suffixes=(\"\", \"_y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = join_df(data['air_visits'], data['holidays'], \"visit_date\", \"calendar_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = join_df(data['test'], data['holidays'], \"visit_date\", \"calendar_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.drop('calendar_date',1,inplace=True) \n",
    "# test.columns\n",
    "# display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop('calendar_date',1,inplace=True) \n",
    "# train.columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.merge(train, stores, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252108, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>35.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>27.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  dow  year  month day_of_week  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13    2  2016      1   Wednesday   \n",
       "1  air_ba937bf13d40fb24  2016-01-14    3  2016      1    Thursday   \n",
       "2  air_ba937bf13d40fb24  2016-01-15    4  2016      1      Friday   \n",
       "3  air_ba937bf13d40fb24  2016-01-16    5  2016      1    Saturday   \n",
       "4  air_ba937bf13d40fb24  2016-01-18    0  2016      1      Monday   \n",
       "\n",
       "   holiday_flg  min_visitors  mean_visitors  median_visitors  max_visitors  \\\n",
       "0        False           7.0      23.843750             25.0          57.0   \n",
       "1        False           2.0      20.292308             21.0          54.0   \n",
       "2        False           4.0      34.738462             35.0          61.0   \n",
       "3        False           6.0      27.651515             27.0          53.0   \n",
       "4        False           2.0      13.754386             12.0          34.0   \n",
       "\n",
       "   count_observations air_genre_name                 air_area_name   latitude  \\\n",
       "0                64.0     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "1                65.0     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2                65.0     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "3                66.0     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "4                57.0     Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "\n",
       "    longitude  visitors  \n",
       "0  139.751599        25  \n",
       "1  139.751599        32  \n",
       "2  139.751599        29  \n",
       "3  139.751599        22  \n",
       "4  139.751599         6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.shape(tr))\n",
    "cols = tr.columns.tolist()\n",
    "cols =  cols[0:5] + cols[6:] + cols[5:6]\n",
    "cols\n",
    "len(cols)\n",
    "final_train = tr[cols]\n",
    "display(final_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = pd.merge(test, stores, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(te))\n",
    "display(te.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.457143</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.350000</td>\n",
       "      <td>24.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.125000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.868421</td>\n",
       "      <td>30.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  dow  year  month day_of_week  \\\n",
       "0  air_00a91d42b08b08d9  2017-04-23    6  2017      4      Sunday   \n",
       "1  air_00a91d42b08b08d9  2017-04-24    0  2017      4      Monday   \n",
       "2  air_00a91d42b08b08d9  2017-04-25    1  2017      4     Tuesday   \n",
       "3  air_00a91d42b08b08d9  2017-04-26    2  2017      4   Wednesday   \n",
       "4  air_00a91d42b08b08d9  2017-04-27    3  2017      4    Thursday   \n",
       "\n",
       "   holiday_flg  min_visitors  mean_visitors  median_visitors  max_visitors  \\\n",
       "0        False           2.0       2.000000              2.0           2.0   \n",
       "1        False           1.0      22.457143             19.0          47.0   \n",
       "2        False           1.0      24.350000             24.5          43.0   \n",
       "3        False          15.0      28.125000             28.0          52.0   \n",
       "4        False          15.0      29.868421             30.0          47.0   \n",
       "\n",
       "   count_observations  air_genre_name                    air_area_name  \\\n",
       "0                 1.0  Italian/French  Tōkyō-to Chiyoda-ku Kudanminami   \n",
       "1                35.0  Italian/French  Tōkyō-to Chiyoda-ku Kudanminami   \n",
       "2                40.0  Italian/French  Tōkyō-to Chiyoda-ku Kudanminami   \n",
       "3                40.0  Italian/French  Tōkyō-to Chiyoda-ku Kudanminami   \n",
       "4                38.0  Italian/French  Tōkyō-to Chiyoda-ku Kudanminami   \n",
       "\n",
       "    latitude   longitude  visitors  \n",
       "0  35.694003  139.753595         0  \n",
       "1  35.694003  139.753595         0  \n",
       "2  35.694003  139.753595         0  \n",
       "3  35.694003  139.753595         0  \n",
       "4  35.694003  139.753595         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.shape(te)\n",
    "cols = te.columns.tolist()\n",
    "cols =  cols[0:5] + cols[6:] + cols[5:6]\n",
    "# cols\n",
    "# len(cols)\n",
    "final_test = te[cols]\n",
    "display(final_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ['air_reserve','hpg_reserve']:\n",
    "    train = pd.merge(final_train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(final_test, data[df], how='left', on=['air_store_id','visit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rv1_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rv1_x'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-452-ee9d4cfa6bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reserv_sum'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rv1_x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rv1_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reserv_mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rv2_x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rv2_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reserv_dt_diff_mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rs2_x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rs2_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_reserv_sum'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rv1_x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rv1_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rv1_x'"
     ]
    }
   ],
   "source": [
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n",
    "\n",
    "col = [c for c in train if c not in ['id', 'air_store_id','visit_date','visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>visitors</th>\n",
       "      <th>rs1</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rs2</th>\n",
       "      <th>rv2</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  dow  year  month day_of_week  \\\n",
       "0  air_ba937bf13d40fb24  2016-01-13    2  2016      1   Wednesday   \n",
       "1  air_ba937bf13d40fb24  2016-01-14    3  2016      1    Thursday   \n",
       "2  air_ba937bf13d40fb24  2016-01-15    4  2016      1      Friday   \n",
       "3  air_ba937bf13d40fb24  2016-01-16    5  2016      1    Saturday   \n",
       "4  air_ba937bf13d40fb24  2016-01-18    0  2016      1      Monday   \n",
       "\n",
       "   holiday_flg  min_visitors  mean_visitors  median_visitors  \\\n",
       "0        False           7.0      23.843750             25.0   \n",
       "1        False           2.0      20.292308             21.0   \n",
       "2        False           4.0      34.738462             35.0   \n",
       "3        False           6.0      27.651515             27.0   \n",
       "4        False           2.0      13.754386             12.0   \n",
       "\n",
       "                ...                 air_genre_name  \\\n",
       "0               ...                     Dining bar   \n",
       "1               ...                     Dining bar   \n",
       "2               ...                     Dining bar   \n",
       "3               ...                     Dining bar   \n",
       "4               ...                     Dining bar   \n",
       "\n",
       "                  air_area_name   latitude   longitude  visitors  rs1  rv1  \\\n",
       "0  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        25  NaN  NaN   \n",
       "1  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        32  NaN  NaN   \n",
       "2  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        29  NaN  NaN   \n",
       "3  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599        22  NaN  NaN   \n",
       "4  Tōkyō-to Minato-ku Shibakōen  35.658068  139.751599         6  NaN  NaN   \n",
       "\n",
       "   rs2  rv2                               id  \n",
       "0  NaN  NaN  air_ba937bf13d40fb24_2016-01-13  \n",
       "1  NaN  NaN  air_ba937bf13d40fb24_2016-01-14  \n",
       "2  NaN  NaN  air_ba937bf13d40fb24_2016-01-15  \n",
       "3  NaN  NaN  air_ba937bf13d40fb24_2016-01-16  \n",
       "4  NaN  NaN  air_ba937bf13d40fb24_2016-01-18  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We have categorical variables we need to transform using entity embeddings\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display(stores.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [data['air_visits'], data['air_reserve'], data['hpg_reserve'], data['air_store'], \n",
    "               data['hpg_store'], data['holidays'], data['store_ids'], data['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tables: display(t.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to combine the hgc data to the air data?? \n",
    "air_store_id\tvisit_date\tvisitors \t air_genre_name\t\t air_area_name\tlatitude\tlongitude\n",
    "day_of_week\t holiday_flg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tables: display(DataFrameSummary(t).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables = [air_visits, air_reserve, hpg_reserve, air_store, \n",
    "#                hpg_store, holidays, store_ids, test]\n",
    "\n",
    "# air_visits, air_store, holidays easy to join\n",
    "# air reserve < air_visits\n",
    "# store_ids !== total air stores\n",
    "# hpg_store > air_store\n",
    "# hpg_reserve > air_visits\n",
    "\n",
    "test needs to get added with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(air_visits), len(test), len(store_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holidays.holiday_flg = holidays.holiday_flg != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def join_df(left, right, left_on, right_on=None):\n",
    "#     if right_on is None: right_on = left_on\n",
    "#     return left.merge(right, how='left', left_on=left_on, right_on=right_on, \n",
    "#                       suffixes=(\"\", \"_y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you sort of remember this but you create a inner join between two files based on identical identifier\n",
    "# in the case of holidays you can join based on the visit_date and calender date.\n",
    "\n",
    "training = join_df(air_visits, holidays, \"visit_date\", \"calendar_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = join_df(test, holidays, \"visit_date\", \"calendar_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# air_visits = join_df(air_visits, air_reserve, \"air_store_id\", \"air_store_id\")\n",
    "# num of unique air_reserve ids !== num of unique air_visit ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training2 = join_df(training, air_store, \"air_store_id\", \"air_store_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training[training.holiday_flg.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training2[training2.air_genre_name.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils2 import *\n",
    "np.set_printoptions(threshold=50, edgeitems=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isoweek import Week\n",
    "from pandas_summary import DataFrameSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_csvs(dirname):\n",
    "    os.chdir(dirname)\n",
    "    filenames=glob.glob(\"*.csv\")\n",
    "\n",
    "    wrote_header = False\n",
    "    with open(\"../\"+dirname+\".csv\",\"w\") as outputfile:\n",
    "        for filename in filenames:\n",
    "            name = filename.split(\".\")[0]\n",
    "            with open(filename) as f:\n",
    "                line = f.readline()\n",
    "                if not wrote_header:\n",
    "                    wrote_header = True\n",
    "                    outputfile.write(\"file,\"+line)\n",
    "                for line in f:\n",
    "                     outputfile.write(name + \",\" + line)\n",
    "                outputfile.write(\"\\n\")\n",
    "\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_csvs('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/midas/pcc/input/air_visit_data.csv')\n",
    "df = pd.read_csv('/Users/midas/pcc/input/air_store_info.csv')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by id and day of week - Median of the visitors is taken\n",
    "agg_data = train.groupby(['air_store_id', 'dow']).agg(aggregation).reset_index()\n",
    "agg_data.columns = ['air_store_id','dow','visitors']\n",
    "agg_data['visitors'] = agg_data['visitors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the first intermediate submission file:\n",
    "merged = pd.merge(test_df, agg_data, how='left', left_on=[\n",
    "    'store_id','dow'], right_on=['air_store_id','dow'])\n",
    "final = merged[['id','visitors']]\n",
    "final.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally from this kernel:\n",
    "# https://www.kaggle.com/zeemeen/weighted-mean-running-10-sec-lb-0-509\n",
    "dfs = { re.search('/([^/\\.]*)\\.csv', fn).group(1):pd.read_csv(\n",
    "    fn) for fn in glob.glob('../input/*.csv')}\n",
    "for k, v in dfs.items(): locals()[k] = v\n",
    "\n",
    "weekend_hdays = date_info.apply(\n",
    "    (lambda x:(x.day_of_week=='Sunday' or x.day_of_week=='Saturday') \n",
    "    and x.holiday_flg==1), axis=1)\n",
    "date_info.loc[weekend_hdays, 'holiday_flg'] = 0\n",
    "date_info['weight'] = (date_info.index + 1) / len(date_info) \n",
    "\n",
    "visit_data = air_visit_data.merge(\n",
    "    date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "visit_data.drop('calendar_date', axis=1, inplace=True)\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "wmean = lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )\n",
    "visitors = visit_data.groupby(\n",
    "    ['air_store_id', 'day_of_week', 'holiday_flg']).apply(wmean).reset_index()\n",
    "visitors.rename(columns={0:'visitors'}, inplace=True) \n",
    "\n",
    "sample_submission['air_store_id'] = sample_submission.id.map(\n",
    "    lambda x: '_'.join(x.split('_')[:-1]))\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(\n",
    "    visitors, on=['air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missings with (air_store_id, day_of_week)\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[visitors.holiday_flg==0], on=(\n",
    "        'air_store_id', 'day_of_week'), how='left')['visitors_y'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missings with (air_store_id)\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), \n",
    "    on='air_store_id', how='left')['visitors_y'].values\n",
    "    \n",
    "sample_submission['visitors'] = sample_submission.visitors.map(pd.np.expm1)\n",
    "sample_submission = sample_submission[['id', 'visitors']]\n",
    "final['visitors'][final['visitors'] ==0] = sample_submission['visitors'][final['visitors'] ==0]\n",
    "sub_file = final.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arithmetric Mean \n",
    "sub_file['visitors'] = np.mean([final['visitors'], sample_submission['visitors']], axis = 0)\n",
    "sub_file.to_csv('sub_math_mean.csv', index=False)\n",
    "\n",
    "## Geometric Mean  \n",
    "sub_file['visitors'] = (final['visitors'] * sample_submission['visitors']) ** (1/2)\n",
    "sub_file.to_csv('sub_geo_mean.csv', index=False)\n",
    "\n",
    "## Harmonic Mean \n",
    "sub_file['visitors'] = 2/(1/final['visitors'] + 1/sample_submission['visitors'])\n",
    "sub_file.to_csv('sub_hrm_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
